{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AAI-511 Final Project\n",
    "\n",
    "Paul Parks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "\n",
    "pretty-midi is used for midi calculations (key, tempo, etc):\n",
    "https://github.com/craffel/pretty-midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pretty_midi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pretty_midi\n",
    "import numpy as np\n",
    "import mido\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, Bidirectional, Attention\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "Data is collected and provided to you.\n",
    "\n",
    "**Dataset**\n",
    "\n",
    "The project will use a dataset consisting of musical scores from various composers. Download the dataset from Kaggle websiteLinks to an external site..\n",
    "\n",
    "https://www.kaggle.com/datasets/blanderbuss/midi-classic-music/data\n",
    "\n",
    "The dataset contains the midi files of compositions from well-known classical composers like Bach, Beethoven, Chopin, and Mozart. The dataset should be labeled with the name of the composer for each score. Please only do your prediction only for below composers, therefore you need to select the required composers from the given dataset above.\n",
    "\n",
    "1. Bach\n",
    "1. Beethoven\n",
    "1. Chopin\n",
    "1. Mozart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing\n",
    "Convert the musical scores into a format suitable for deep learning models. This involves converting the musical scores into MIDI files and applying data augmentation techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of MIDI files: 1530\n",
      "Number of labels: 1530\n",
      "Bach: 925\n",
      "Beethoven: 212\n",
      "Chopin: 136\n",
      "Mozart: 257\n"
     ]
    }
   ],
   "source": [
    "def load_midi_files(base_dir, composers):\n",
    "    midi_files = []\n",
    "    labels = []\n",
    "\n",
    "    for composer in composers:\n",
    "        composer_dir = os.path.join(base_dir, composer)\n",
    "        for root, _, files in os.walk(composer_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.mid') or file.endswith('.midi'):\n",
    "                    midi_files.append(os.path.join(root, file))\n",
    "                    labels.append(composer)\n",
    "    return midi_files, labels\n",
    "\n",
    "base_dir = './Dataset/midiclassics/'\n",
    "composers = ['Bach', 'Beethoven', 'Chopin', 'Mozart']\n",
    "\n",
    "midi_files, labels = load_midi_files(base_dir, composers)\n",
    "\n",
    "print('Number of MIDI files:', len(midi_files))\n",
    "print('Number of labels:', len(labels))\n",
    "\n",
    "# print files per composer\n",
    "for composer in composers:\n",
    "    print(f'{composer}: {labels.count(composer)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "Extract features from the MIDI files, such as notes, chords, and tempo, using music analysis tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paula\\AppData\\Roaming\\Python\\Python39\\site-packages\\pretty_midi\\pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing ./Dataset/midiclassics/Beethoven\\Anhang 14-3.mid: Could not decode key with 3 flats and mode 255\n",
      "Skipping ./Dataset/midiclassics/Beethoven\\Anhang 14-3.mid\n",
      "Error processing ./Dataset/midiclassics/Mozart\\Piano Sonatas\\Nueva carpeta\\K281 Piano Sonata n03 3mov.mid: Could not decode key with 2 flats and mode 2\n",
      "Skipping ./Dataset/midiclassics/Mozart\\Piano Sonatas\\Nueva carpeta\\K281 Piano Sonata n03 3mov.mid\n"
     ]
    }
   ],
   "source": [
    "def pad_or_truncate(array, max_length):\n",
    "    array = np.array(array)\n",
    "    array = array[array > 0]\n",
    "    if len(array) > max_length:\n",
    "        return array[:max_length]\n",
    "    else:\n",
    "        return np.pad(array, (0, max_length - len(array)), 'constant')\n",
    "\n",
    "def extract_chords(midi_data, time_window=0.05):\n",
    "    chords = []\n",
    "    for instrument in midi_data.instruments:\n",
    "        if not instrument.is_drum:\n",
    "            notes = sorted(instrument.notes, key=lambda note: note.start)\n",
    "            current_chord = []\n",
    "            current_start_time = notes[0].start if notes else None\n",
    "            \n",
    "            for note in notes:\n",
    "                if current_start_time is not None and note.start - current_start_time > time_window:\n",
    "                    if len(current_chord) > 1:\n",
    "                        chords.append(current_chord)\n",
    "                    current_chord = []\n",
    "                    current_start_time = note.start\n",
    "                \n",
    "                current_chord.append(note)\n",
    "            \n",
    "            if len(current_chord) > 1:\n",
    "                chords.append(current_chord)\n",
    "    \n",
    "    return chords\n",
    "\n",
    "COMMON_CHORDS = {\n",
    "    'major': (0, 4, 7),\n",
    "    'minor': (0, 3, 7),\n",
    "    'diminished': (0, 3, 6),\n",
    "    'augmented': (0, 4, 8),\n",
    "    'dominant_seventh': (0, 4, 7, 10),\n",
    "    'major_seventh': (0, 4, 7, 11),\n",
    "    'minor_seventh': (0, 3, 7, 10),\n",
    "    'suspended_fourth': (0, 5, 7),\n",
    "    'suspended_second': (0, 2, 7),\n",
    "    'perfect_fourth': (0, 5, 9),\n",
    "    'sixth_chord': (0, 4, 9),\n",
    "    'unknown_1': (0, 4, 5, 9),\n",
    "    'unknown_2': (0, 6, 9),\n",
    "    'unknown_3': (0, 2, 6, 9),\n",
    "    'unknown_4': (2, 5, 11),\n",
    "    'unknown_5': (3, 6, 11),\n",
    "    'unknown_6': (1, 6, 11),\n",
    "    'other': (),\n",
    "}\n",
    "\n",
    "def extract_chord_histogram(midi_data, common_chords=COMMON_CHORDS, time_window=0.05):\n",
    "    histogram = {chord: 0 for chord in common_chords}\n",
    "    unknown_chords = set()\n",
    "    chords = extract_chords(midi_data, time_window)\n",
    "    \n",
    "    for chord in chords:\n",
    "        pitches = sorted(set(note.pitch % 12 for note in chord))\n",
    "        if len(pitches) >= 3:\n",
    "            recognized = False\n",
    "            for chord_name, intervals in common_chords.items():\n",
    "                if len(pitches) == len(intervals):\n",
    "                    if all((pitches[i+1] - pitches[i]) % 12 == intervals[i+1] - intervals[i] for i in range(len(intervals) - 1)):\n",
    "                        histogram[chord_name] += 1\n",
    "                        recognized = True\n",
    "                        break\n",
    "            if not recognized:\n",
    "                histogram['other'] += 1\n",
    "                unknown_chords.add(tuple(pitches))\n",
    "    \n",
    "    return np.array(list(histogram.values())), unknown_chords\n",
    "\n",
    "def extract_tempo(midi_data):\n",
    "    tempos = midi_data.get_tempo_changes()\n",
    "    return tempos\n",
    "\n",
    "def extract_key_signature(midi_data):\n",
    "    key_signatures = midi_data.key_signature_changes\n",
    "    if key_signatures:\n",
    "        key_signature = key_signatures[0].key_number\n",
    "    else:\n",
    "        key_signature = 0  # C major or A minor\n",
    "    return key_signature\n",
    "\n",
    "def transpose_to_c_major(midi_data):\n",
    "    key_signature_changes = midi_data.key_signature_changes\n",
    "    if key_signature_changes:\n",
    "        original_key = key_signature_changes[0].key_number\n",
    "        semitones_to_c_major = -original_key\n",
    "        for instrument in midi_data.instruments:\n",
    "            for note in instrument.notes:\n",
    "                note.pitch += semitones_to_c_major\n",
    "    return midi_data\n",
    "\n",
    "def extract_note_histogram(midi_data):\n",
    "    histogram = np.zeros(12)\n",
    "    for instrument in midi_data.instruments:\n",
    "        if not instrument.is_drum:\n",
    "            for note in instrument.notes:\n",
    "                histogram[note.pitch % 12] += 1\n",
    "    return histogram\n",
    "\n",
    "def extract_features(midi_file):\n",
    "    try:\n",
    "        midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
    "        key_signature = extract_key_signature(midi_data)\n",
    "        midi_data = transpose_to_c_major(midi_data)\n",
    "        note_histogram = extract_note_histogram(midi_data)\n",
    "        tempos = extract_tempo(midi_data)\n",
    "        chord_histogram, unknown_chords = extract_chord_histogram(midi_data)\n",
    "        pitch_classes, durations = extract_pitch_classes_and_durations(midi_data)\n",
    "\n",
    "        return note_histogram, chord_histogram, tempos, key_signature, pitch_classes\n",
    "    except (mido.KeySignatureError, KeyError) as e:\n",
    "        print(f\"Error processing {midi_file}: {e}\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "def extract_pitch_classes_and_durations(midi_data):\n",
    "    pitch_classes = []\n",
    "    durations = []\n",
    "    for instrument in midi_data.instruments:\n",
    "        if not instrument.is_drum:\n",
    "            for note in instrument.notes:\n",
    "                pitch_classes.append(note.pitch % 12)  # Convert to pitch class\n",
    "                durations.append(note.end - note.start)\n",
    "    return pitch_classes, durations\n",
    "\n",
    "def prepare_feature_data(composers):\n",
    "    MAX_TEMPOS = 5\n",
    "\n",
    "    rows = [] \n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for i, file in enumerate(midi_files):\n",
    "        composer = labels[i]\n",
    "        note_histogram, chord_histogram, tempos, key_signature, pitch_classes = extract_features(file)\n",
    "        if note_histogram is not None:\n",
    "            tempos = pad_or_truncate(tempos[1], MAX_TEMPOS) if len(tempos) > 1 else np.zeros(MAX_TEMPOS)\n",
    "\n",
    "            rows.append({\n",
    "                'composer': composer,\n",
    "                'note_histogram': note_histogram,\n",
    "                'chord_histogram': chord_histogram,\n",
    "                'tempos': tempos,\n",
    "                'key_signature': key_signature\n",
    "            })\n",
    "\n",
    "            \n",
    "            sequence_length = 100\n",
    "            # trim or pad the pitch classes to the sequence length\n",
    "            pitch_classes = pad_or_truncate(pitch_classes, sequence_length)\n",
    "            \n",
    "\n",
    "            features = np.concatenate([\n",
    "                note_histogram.flatten(),\n",
    "                chord_histogram.flatten(),\n",
    "                tempos.flatten(),\n",
    "                np.array([key_signature]),\n",
    "            ])\n",
    "            X.append(features)\n",
    "\n",
    "            y.append(composers.index(composer))\n",
    "        else:\n",
    "            print(f\"Skipping {file}\")\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    X = pad_sequences(X, maxlen=sequence_length, padding='post')\n",
    "\n",
    "    X_arr = np.array(X)\n",
    "    y_arr = np.array(y)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_arr = scaler.fit_transform(X_arr)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_arr, y_arr, test_size=0.2, random_state=42)\n",
    "    return df, X, y, X_train, X_val, y_train, y_val\n",
    "\n",
    "# Usage\n",
    "df, X, y, X_train, X_val, y_train, y_val = prepare_feature_data(composers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>composer</th>\n",
       "      <th>note_histogram</th>\n",
       "      <th>chord_histogram</th>\n",
       "      <th>tempos</th>\n",
       "      <th>key_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bach</td>\n",
       "      <td>[136.0, 5.0, 72.0, 12.0, 65.0, 181.0, 4.0, 112...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[120.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bach</td>\n",
       "      <td>[759.0, 195.0, 583.0, 863.0, 132.0, 806.0, 74....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[75.0, 70.00007000007, 65.000065000065, 50.0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bach</td>\n",
       "      <td>[868.0, 82.0, 646.0, 648.0, 122.0, 691.0, 85.0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[80.0, 78.00007800007802, 75.0, 70.00023333411...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bach</td>\n",
       "      <td>[624.0, 214.0, 860.0, 145.0, 710.0, 711.0, 147...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[60.0, 50.0, 30.0, 60.0, 55.000004583333705]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bach</td>\n",
       "      <td>[295.0, 243.0, 446.0, 139.0, 671.0, 70.0, 554....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[40.0, 75.0, 70.00007000007, 65.000065000065, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  composer                                     note_histogram  \\\n",
       "0     Bach  [136.0, 5.0, 72.0, 12.0, 65.0, 181.0, 4.0, 112...   \n",
       "1     Bach  [759.0, 195.0, 583.0, 863.0, 132.0, 806.0, 74....   \n",
       "2     Bach  [868.0, 82.0, 646.0, 648.0, 122.0, 691.0, 85.0...   \n",
       "3     Bach  [624.0, 214.0, 860.0, 145.0, 710.0, 711.0, 147...   \n",
       "4     Bach  [295.0, 243.0, 446.0, 139.0, 671.0, 70.0, 554....   \n",
       "\n",
       "                                     chord_histogram  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                              tempos  key_signature  \n",
       "0                        [120.0, 0.0, 0.0, 0.0, 0.0]              0  \n",
       "1  [75.0, 70.00007000007, 65.000065000065, 50.0, ...              0  \n",
       "2  [80.0, 78.00007800007802, 75.0, 70.00023333411...              0  \n",
       "3       [60.0, 50.0, 30.0, 60.0, 55.000004583333705]              0  \n",
       "4  [40.0, 75.0, 70.00007000007, 65.000065000065, ...              0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 1528\n",
      "Number of labels: 1528\n",
      "Feature vector length: 100\n",
      "Unique labels: {0, 1, 2, 3}\n",
      "Bach: 925\n",
      "Beethoven: 211\n",
      "Chopin: 136\n",
      "Mozart: 256\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples:', len(X))\n",
    "print('Number of labels:', len(y))\n",
    "print('Feature vector length:', len(X[0]))\n",
    "\n",
    "# count unique labels\n",
    "unique_labels = set(y)\n",
    "print('Unique labels:', unique_labels)\n",
    "\n",
    "# Count samples per label\n",
    "for label in unique_labels:\n",
    "    print(f'{composers[label]}: {y.count(label)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "Develop a deep learning model using LSTM and CNN architectures to classify the musical scores according to the composer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X_train.shape[1], 1)\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(128, input_shape=input_shape, return_sequences=True))\n",
    "# model.add(LSTM(64, return_sequences=False))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(len(composers), activation='softmax'))\n",
    "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=input_shape))\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=False)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(len(composers), activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "Train the deep learning model using the pre-processed and feature-extracted data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "39/39 [==============================] - 4s 41ms/step - loss: 1.2136 - accuracy: 0.6097 - val_loss: 1.2214 - val_accuracy: 0.6275\n",
      "Epoch 2/100\n",
      "39/39 [==============================] - 1s 21ms/step - loss: 1.1026 - accuracy: 0.6277 - val_loss: 1.1280 - val_accuracy: 0.5719\n",
      "Epoch 3/100\n",
      "39/39 [==============================] - 1s 20ms/step - loss: 1.0089 - accuracy: 0.6318 - val_loss: 1.0547 - val_accuracy: 0.5882\n",
      "Epoch 4/100\n",
      "39/39 [==============================] - 1s 20ms/step - loss: 0.9213 - accuracy: 0.6530 - val_loss: 1.0425 - val_accuracy: 0.5719\n",
      "Epoch 5/100\n",
      "39/39 [==============================] - 1s 20ms/step - loss: 0.9116 - accuracy: 0.6604 - val_loss: 1.0525 - val_accuracy: 0.5719\n",
      "Epoch 6/100\n",
      "39/39 [==============================] - 1s 20ms/step - loss: 0.8907 - accuracy: 0.6448 - val_loss: 0.9976 - val_accuracy: 0.5752\n",
      "Epoch 7/100\n",
      "39/39 [==============================] - 1s 20ms/step - loss: 0.8780 - accuracy: 0.6588 - val_loss: 0.9592 - val_accuracy: 0.6078\n",
      "Epoch 8/100\n",
      "39/39 [==============================] - 1s 20ms/step - loss: 0.8912 - accuracy: 0.6457 - val_loss: 0.9409 - val_accuracy: 0.5882\n",
      "Epoch 9/100\n",
      "39/39 [==============================] - 1s 20ms/step - loss: 0.8506 - accuracy: 0.6759 - val_loss: 0.9020 - val_accuracy: 0.6209\n",
      "Epoch 10/100\n",
      "39/39 [==============================] - 1s 20ms/step - loss: 0.8637 - accuracy: 0.6694 - val_loss: 0.8767 - val_accuracy: 0.6176\n",
      "Epoch 11/100\n",
      "39/39 [==============================] - 1s 20ms/step - loss: 0.8586 - accuracy: 0.6579 - val_loss: 0.9133 - val_accuracy: 0.5980\n",
      "Epoch 12/100\n",
      "39/39 [==============================] - 1s 20ms/step - loss: 0.8615 - accuracy: 0.6612 - val_loss: 0.9018 - val_accuracy: 0.6275\n",
      "Epoch 13/100\n",
      "39/39 [==============================] - 1s 20ms/step - loss: 0.8424 - accuracy: 0.6571 - val_loss: 0.8270 - val_accuracy: 0.6601\n",
      "Epoch 14/100\n",
      "39/39 [==============================] - 1s 20ms/step - loss: 0.8176 - accuracy: 0.6800 - val_loss: 0.8781 - val_accuracy: 0.6144\n",
      "Epoch 15/100\n",
      "39/39 [==============================] - 1s 20ms/step - loss: 0.8205 - accuracy: 0.6645 - val_loss: 0.8651 - val_accuracy: 0.6373\n",
      "Epoch 16/100\n",
      "39/39 [==============================] - 1s 20ms/step - loss: 0.8096 - accuracy: 0.6759 - val_loss: 0.9213 - val_accuracy: 0.6471\n",
      "Epoch 17/100\n",
      "39/39 [==============================] - 1s 20ms/step - loss: 0.8363 - accuracy: 0.6784 - val_loss: 0.8990 - val_accuracy: 0.6438\n",
      "Epoch 18/100\n",
      "39/39 [==============================] - 1s 20ms/step - loss: 0.8171 - accuracy: 0.6735 - val_loss: 0.8597 - val_accuracy: 0.6307\n",
      "Epoch 19/100\n",
      "39/39 [==============================] - 1s 20ms/step - loss: 0.7860 - accuracy: 0.6874 - val_loss: 0.8745 - val_accuracy: 0.6405\n",
      "Epoch 20/100\n",
      "39/39 [==============================] - 1s 20ms/step - loss: 0.7974 - accuracy: 0.6645 - val_loss: 0.8770 - val_accuracy: 0.6471\n",
      "Epoch 21/100\n",
      "39/39 [==============================] - 1s 20ms/step - loss: 0.7796 - accuracy: 0.6841 - val_loss: 0.8779 - val_accuracy: 0.6634\n",
      "Epoch 22/100\n",
      "39/39 [==============================] - 1s 20ms/step - loss: 0.7843 - accuracy: 0.6825 - val_loss: 0.9105 - val_accuracy: 0.6634\n",
      "Epoch 23/100\n",
      "39/39 [==============================] - 1s 20ms/step - loss: 0.7900 - accuracy: 0.6915 - val_loss: 0.9208 - val_accuracy: 0.6373\n"
     ]
    }
   ],
   "source": [
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Model Training\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "Evaluate the performance of the deep learning model using accuracy, precision, and recall metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6601307392120361\n",
      "10/10 [==============================] - 1s 7ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Bach       0.73      0.93      0.81       175\n",
      "   Beethoven       0.47      0.33      0.39        57\n",
      "      Chopin       0.50      0.46      0.48        28\n",
      "      Mozart       0.47      0.17      0.25        46\n",
      "\n",
      "    accuracy                           0.66       306\n",
      "   macro avg       0.54      0.47      0.49       306\n",
      "weighted avg       0.62      0.66      0.62       306\n",
      "\n",
      "[[162   4   2   7]\n",
      " [ 27  19   9   2]\n",
      " [ 10   5  13   0]\n",
      " [ 24  12   2   8]]\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "\n",
    "# Calculate additional metrics\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_val, y_pred_classes, target_names=composers))\n",
    "conf_matrix = confusion_matrix(y_val, y_pred_classes)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Optimization\n",
    "Optimize the deep learning model by fine-tuning hyperparameters.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msaai-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
